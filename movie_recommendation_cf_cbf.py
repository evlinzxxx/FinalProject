# -*- coding: utf-8 -*-
"""movie-recommendation-cf-cbf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14uhOp_psmV7wV5dVdEGVHuq92OmJdmPI

## Import Library

Install opendatasets yaitu library untuk mendownload dataset
"""

!pip install opendatasets

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import opendatasets as od

from nltk.tokenize import word_tokenize
from pathlib import Path
from zipfile import ZipFile

from tensorflow import keras
from keras.callbacks import EarlyStopping
from tensorflow.keras import layers
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Embedding, Flatten, Concatenate, Input

from sklearn.impute import SimpleImputer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""## Data Understanding

1.Download dataset yang dibutuhkan yaitu **Movie Recommendation Data** yang didapat dari situs **Kaggle**, dari tautan berikut [movie-recommendation-data](https://www.kaggle.com/rohan4050/movie-recommendation-data), dengan menambah baris code seperti berikut, memasukkan username dan account number akun kaggle :
"""

od.download('https://www.kaggle.com/rohan4050/movie-recommendation-data?select=ml-latest-small')

"""2.Selanjutnya, baca dan proses data-data yang sudah di download dengan menggunakan fungsi **pd.read_csv**"""

ratings = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/ratings.csv')
movies = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/movies.csv')
links = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/links.csv')
tags = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/tags.csv')

"""3.Dataset Link

Melakukan eksplorasi variabel links, merupakan daftar link movie tersebut.

3.1 Melihat informasi variabel dalam dataset link
"""

links.info()

"""Output kode di atas memberikan informasi :

* Total baris ada 9724
* Total kolom ada 3
* Terdapat 3 kolom bertipe data numerik

Menampilkan 5 sampel teratas dari varibel links.
"""

links.head()

"""4.Dataset Movies

Melakukan eksplorasi variabel movies yang merupakan daftar movie yang tersedia.

4.1 Melihat informasi variabel dalam dataset movie
"""

movies.info()

"""Output kode di atas memberikan informasi :

* Total baris ada 9724
* Total kolom ada 3
* Terdapat 1 kolom bertipe data numerik
* Terdapat 1 kolom bertipe data object

Menampilkan 5 sampel teratas dari varibel movies.
"""

movies.head()

"""5.Dataset Tags

Melakukan eksplorasi variabel tags yang merupakan daftar tags (tagar) yang tersedia.

5.1 Melihat informasi variabel dalam dataset tags
"""

tags.info()

"""Output kode di atas memberikan informasi :

* Total baris ada 3683
* Total kolom ada 4
* Terdapat 3 kolom bertipe data numerik
* Terdapat 1 kolom bertipe data object

Menampilkan 5 sampel teratas dari varibel tags.
"""

tags.head()

"""6.Dataset Ratings

Melakukan eksplorasi data yang akan digunakan pada model yaitu data ratings.

6.1 Melihat informasi variabel dalam dataset Ratings
"""

ratings.info()

"""Output kode di atas memberikan informasi :

* Total baris ada 100836
* Total kolom ada 4
* Terdapat 4 kolom bertipe data numerik

Menampilkan 5 sampel teratas dari varibel ratings.
"""

ratings.head()

"""7.Melakukan pengecekan nilai data dari data ratings"""

ratings.describe()

"""Dari output di atas, diketahui bahwa :
* Nilai maksimum ratings adalah 5.0 atau 5
* Nilai minimumnya adalah 0.5.
* Artinya, skala rating berkisar antara 0.5 hingga 5.

## Data Preprocessing


1.Menggabungkan Movie

Menggabungkan data dari file berbeda (links, movies, ratings, tags) menggunakan pd.merge().
"""

movie_all = np.concatenate((
    links.movieId.unique(),
    movies.movieId.unique(),
    ratings.movieId.unique(),
    tags.movieId.unique(),
))

movie_all = np.sort(np.unique(movie_all))

print('Jumlah seluruh data movie berdasarkan movieID: ', len(movie_all))

"""Terdapat 9742 judul movie yang akan digunakan untuk melakukan proses rekomendasi

2.Menggabungkan Seluruh User

Menggabungkan beberapa file dengan fungsi concatenate berdasarkan pada userId, gabungkan seluruh data pada variabel user_all
"""

user_all = np.concatenate((
    ratings.userId.unique(),
    tags.userId.unique()))

user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

"""Terdapat 610 user yang sudah memberikan nilai pada data rating

3.Menggabungkan file links, movies, ratingsm tags ke dalam dataframe movie_info. Serta menggabungkan dataframe ratings dengan movie_info berdasarkan nilai movieId
"""

movie_info = pd.concat([links, movies, ratings, tags])
movie = pd.merge(ratings, movie_info , on='movieId', how='left')
movie

"""Setelah digabungkan semua variabel lalu akhirnya terkumpul sebanyak 6359585 baris dan 12 kolom, tetapi bisa dilihat masih banyak data yang missing value atau kosong

4.Seperti yang dilihat dari hasil diatas terdapat banyak sekali missing value maka lakukan cek missing value. Proses ini dilakukan menggunakan bantuan kode .sum()
"""

movie.isnull().sum()

"""Kemudian tabel di atas menunjukkan bahwa terdapat 8 kolom yang memiliki data yang missing dan 4 data lain yang tidak ada missing value nya

5.Kemudian melakukan penggabungan rating berdasarkan movieId

* Proses ini menggunakan fungsi groupby untuk mengelompokkan data berdasarkan kolom movieId dan menjumlahkan data dalam kolom lainnya seperti rating, timestamp, dan lain-lain.
*Hasilnya adalah data agregat yang menunjukkan informasi terakumulasi untuk setiap film.
"""

movie.groupby('movieId').sum()

"""6.Menggabungkan Data dengan Fitur Nama Movie

Mendefinisikan variabel all_movie_rate dengan variabel ratings. Data ratings diproses ke dalam variabel all_movie_rate untuk digunakan lebih lanjut dalam penggabungan data. Data ini mencakup informasi userId, movieId, rating, dan timestamp.
"""

all_movie_rate = ratings
all_movie_rate

"""7.Menggabungkan all movie_rate dengan dataframe movies berdasarkan movieId
* Data all_movie_rate digabungkan dengan dataframe movies berdasarkan kolom movieId menggunakan merge.
* Data yang dihasilkan mencakup informasi film seperti title dan genres yang ditambahkan ke setiap entri rating.
"""

all_movie_name = pd.merge(all_movie_rate, movies[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

"""8.Menggabungkan dataframe tags dengan all_movie_name berdasarkan movieId
* Data gabungan dari langkah sebelumnya digabungkan lagi dengan dataframe tags berdasarkan movieId.
* Kolom tag ditambahkan untuk memberikan konteks tambahan berupa deskripsi atau label terkait film.
"""

all_movie = pd.merge(all_movie_name, tags[['movieId','tag']], on='movieId', how='left')
all_movie

"""## Data Preparation


1.Mengatasi Missing Value

Untuk memeriksa apakah masih terdapat data yang hilang (missing values) dalam sebuah dataset, kita bisa menggunakan metode **.isnull()** untuk mendeteksi nilai yang kosong (NaN), kemudian mengkombinasikannya dengan **.sum()** untuk menghitung jumlah nilai kosong di setiap kolom.
"""

all_movie.isnull().sum()

"""Setelah melakukan pemeriksaan data menggunakan metode .isnull().sum(), kita menemukan bahwa hampir semua kolom dalam dataset telah terisi dengan baik, kecuali satu kolom, yaitu tag, yang masih memiliki nilai kosong atau missing value. Berdasarkan hasil analisis, kolom tag memiliki sebanyak **52.549** nilai kosong. Hal ini menunjukkan bahwa sebagian besar film atau entitas dalam dataset belum memiliki tag atau label deskriptif yang relevan.

2.Setelah analisis awal dilakukan, ditemukan bahwa dalam dataset terdapat data kosong (missing values) pada beberapa kolom tertentu, khususnya pada kolom tag.

Untuk memastikan bahwa dataset bersih dan siap digunakan dalam analisis lanjutan atau implementasi model machine learning, langkah selanjutnya adalah melakukan pembersihan data. Salah satu metode pembersihan yang umum digunakan adalah dengan memanfaatkan fungsi **dropna()**. Fungsi ini memungkinkan kita untuk menghapus seluruh baris atau kolom yang mengandung nilai kosong, sehingga hanya data yang lengkap yang akan tersisa dalam dataset.
"""

all_movie_clean = all_movie.dropna()
all_movie_clean

"""Setelah proses pembersihan data menggunakan fungsi dropna(), jumlah total baris dalam dataset mengalami pengurangan. Dataset yang semula memiliki 285.762 baris kini berkurang menjadi 233.213 baris. Pengurangan ini terjadi karena baris-baris yang memiliki nilai kosong pada salah satu kolom, khususnya kolom tag, telah dihapus dari dataset.

3.Lalu periksa kembali missing value pada variabel all_movie_clean dengan memeriksa apakah masih terdapat data yang hilang (missing values) dalam sebuah dataset, kita bisa menggunakan metode .isnull() untuk mendeteksi nilai yang kosong (NaN), kemudian mengkombinasikannya dengan .sum() untuk menghitung jumlah nilai kosong di setiap kolom.
"""

all_movie_clean.isnull().sum()

"""Sudah tidak ada lagi data yang memiliki missing value

4.Langkah selanjutnya adalah mengurutkan data film dalam dataset berdasarkan **movieId**, sehingga semua informasi terkait setiap film tersusun rapi dan terorganisasi dengan baik.

Dalam langkah ini, metode yang digunakan untuk mengurutkan data adalah fungsi **sort_values** dari pustaka Pandas. Fungsi ini memungkinkan pengurutan data berdasarkan kolom tertentu, dalam hal ini kolom movieId, dengan parameter **ascending=True** yang berarti pengurutan dilakukan secara ascending atau dari nilai terkecil ke terbesar.

Setelah pengurutan selesai, hasilnya disimpan ke dalam variabel baru bernama fix_movie, yang merupakan dataset hasil pengurutan dari all_movie_clean.

Penggunaan sort_values memastikan bahwa data terorganisasi dengan baik, memudahkan analisis data lebih lanjut, dan menjaga keterkaitan antar baris data. Langkah ini sangat penting untuk mempersiapkan data sebelum digunakan pada algoritma rekomendasi atau analisis lainnya yang sensitif terhadap urutan data.
"""

fix_movie = all_movie_clean.sort_values('movieId', ascending=True)
fix_movie

"""Hasil akhirnya adalah dataset yang telah tersusun rapi berdasarkan kolom movieId, yang memberikan struktur yang lebih terorganisasi untuk proses pengolahan data selanjutnya.

5.Mengecek berapa jumlah fix_movie
"""

len(fix_movie.movieId.unique())

"""Terdapat 1554 data fix untuk id movie yang akan digunakan

6.Membuat variabel preparation yang berisi dataframe fix_movie kemudian mengurutkan berdasarkan movieId
"""

preparation = fix_movie
preparation.sort_values('movieId')

"""7.Selanjutnya, gunakan data unik untuk dimasukkan ke dalam proses pemodelan.
serta hapus data duplicate dengan fungsi **drop_duplicates()** berdasarkan movieId

Langkah ini bertujuan untuk memastikan bahwa setiap movieId yang digunakan dalam proses pemodelan bersifat unik, sehingga tidak ada data duplikat yang dapat menyebabkan bias atau gangguan dalam analisis atau pemodelan sistem rekomendasi.

Berikut adalah penjelasan prosesnya:

* Menghapus Duplikasi Data
Fungsi **drop_duplicates()** digunakan untuk menghapus baris yang memiliki nilai duplikat pada kolom movieId.

* Parameter subset='movieId': Menentukan bahwa pengecekan duplikasi hanya dilakukan pada kolom movieId.
Data yang dianggap duplikat adalah data dengan movieId yang sama, meskipun nilai di kolom lainnya berbeda.
"""

preparation = preparation.drop_duplicates('movieId')
preparation

"""Setelah proses ini, hanya akan ada satu baris untuk setiap movieId, memastikan bahwa data unik digunakan dalam proses pemodelan. Hasilnya disimpan kembali dalam variabel preparation, menggantikan dataset sebelumnya.

8.Selanjutnya,  melakukan konversi data series menjadi list. Dalam hal ini, menggunakan fungsi `tolist()` dari library numpy.

Langkah ini berfungsi untuk mengonversi kolom data dari tipe Series dalam DataFrame menjadi list. Proses ini penting karena banyak algoritma atau model lebih mudah memproses data dalam bentuk list atau array daripada DataFrame langsung. Berikut adalah penjelasan langkah demi langkah:

1. Mengonversi Kolom Data Menjadi List
* `preparation['movieId'].tolist()`: Mengonversi kolom movieId yang awalnya dalam bentuk Series menjadi list. Setiap elemen dalam kolom ini akan menjadi elemen dalam list baru, yang memungkinkan penggunaan data tersebut dalam proses lain seperti pemodelan atau visualisasi.
* `preparation['title'].tolist()`: Mengonversi kolom title yang berisi nama-nama film menjadi list. Setiap elemen yang sebelumnya merupakan nilai dalam kolom title sekarang menjadi elemen list.
* `preparation['genres'].tolist()`: Mengonversi kolom genres yang berisi genre film menjadi list. Dengan cara ini, informasi genre film dalam dataset dapat lebih mudah dianalisis atau digunakan dalam pemrosesan lebih lanjut.
2. Menampilkan Jumlah Data
* Fungsi `len()` digunakan untuk menghitung jumlah elemen dalam setiap list yang baru dibuat.
* `print(len(movie_id))`, `print(len(movie_name))`, dan print`(len(movie_genre))` digunakan untuk menampilkan jumlah elemen dalam masing-masing list movie_id, movie_name, dan movie_genre.
"""

movie_id = preparation['movieId'].tolist()
movie_name = preparation['title'].tolist()
movie_genre = preparation['genres'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

"""Hasil tersebut menunjukkan bahwa setelah konversi, terdapat 1554 entri untuk masing-masing kolom movieId, title, dan genres dalam dataset yang telah diproses. Ini berarti bahwa dalam dataset yang telah dibersihkan dan diolah, ada 1554 film unik berdasarkan movieId yang memiliki data terkait title dan genres.

9.Membuat dictionary untuk menentukan pasangan key-value pada data movie_id, movie_name, dan movie_genre yang telah disiapkan sebelumnya.
Berikut adalah penjelasan dari proses tersebut:

1. Membuat DataFrame: Dengan menggunakan fungsi `pd.DataFrame()`, kamu menyusun data yang sudah ada dalam tiga list (movie_id, movie_name, movie_genre) menjadi sebuah struktur data tabular (DataFrame) yang berisi tiga kolom:
- id: Berisi movieId (ID unik untuk setiap film).
- movie_name: Berisi nama film (title).
- genre: Berisi genre yang terkait dengan masing-masing film.

2. Menyusun Key-Value: Setiap baris dalam movie_new merepresentasikan pasangan key-value untuk film tertentu, di mana:
- Key: id (movieId)
- Value: Pasangan movie_name dan genre
"""

movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""Dengan membentuk movie_new, kita telah merapikan data dan mempersiapkannya dalam bentuk yang sangat sesuai untuk analisis atau pemodelan lebih lanjut.Dictionary ini memberi hubungan langsung antara movieId dengan title dan genre. Ini sangat berguna untuk pemodelan rekomendasi di mana kita dapat dengan mudah menghubungkan film dengan genre dan nama filmnya. Dengan total data 1554 baris dan 3 kolom

## Modeling and Result

Proses modeling yang dilakukan adalah dengan algoritma machine learning, yaitu **content based filtering** dan **collabrative filtering**. untuk algoritma content based filtering saya buat dengan apa yang disukai pengguna pada masa lalu, sedangkan untuk content based filtering, saya buat dengan memanfaatkan tingkat rating dari movie tersebut.

### **1. Content Based Filtering**

**TF-IDF Vectorizer**:

1.Genre setiap film diubah menjadi vektor numerik menggunakan TfidfVectorizer.
Menghasilkan matriks tf-idf untuk menghitung relevansi antar film.
Proses TF-IDF (Term Frequency - Inverse Document Frequency)
- Tujuan:

  TF-IDF adalah metode untuk mengubah teks (seperti genre film dalam sistem rekomendasi) menjadi representasi numerik (vektor) yang dapat diproses lebih lanjut oleh model machine learning. Ini digunakan untuk mengukur pentingnya kata dalam dokumen relatif terhadap seluruh koleksi dokumen (corpus).

- Langkah-langkah TF-IDF:

  1. Term Frequency (TF):
  
      Menghitung frekuensi kemunculan kata dalam dokumen (dalam hal ini genre).

      TF
(
ùë°
)
=
Jumlah¬†kemunculan¬†kata¬†t¬†dalam¬†dokumen /
Jumlah¬†total¬†kata¬†dalam¬†dokumen

  2. Inverse Document Frequency (IDF):

      Mengukur seberapa penting kata tersebut secara global dalam seluruh koleksi dokumen. Kata yang sering muncul di seluruh dokumen diberi bobot rendah.

      IDF
(
ùë°
)
=
log
‚Å°
(
Total¬†dokumen /
Jumlah¬†dokumen¬†yang¬†mengandung¬†kata¬†t
 )
      TF-IDF:
Hasil dari mengalikan TF dan IDF. Semakin sering sebuah kata muncul dalam satu dokumen, namun jarang di dokumen lain, semakin tinggi bobotnya.

      TF-IDF
(
ùë°
)
=
TF
(
ùë°
)
√ó
IDF
(
ùë°
)
- Implementasi di kode:

  `TfidfVectorizer()`:
Fungsi ini digunakan untuk mengubah teks genre film menjadi vektor numerik berdasarkan TF-IDF.

  `fit()`:
Proses ini "melatih" model dengan seluruh data genre dari film.

  `get_feature_names_out()`:
Menampilkan daftar kata-kata yang dikenali oleh TfidfVectorizer, yaitu fitur yang digunakan untuk representasi vektor genre.
"""

tf = TfidfVectorizer()
tf.fit(movie_new['genre'])
tf.get_feature_names_out()

"""Hasil dari `tf.get_feature_names_out()` yang didapatkan adalah daftar kata atau fitur yang diambil dari genre film yang ada di dataset. Setiap kata ini mewakili elemen unik yang ditemukan dalam kolom genre film. Dengan menggunakan TF-IDF, setiap genre akan diubah menjadi vektor numerik, dan setiap kata di dalam genre akan dihitung berdasarkan frekuensi kata tersebut muncul dalam masing-masing film serta seberapa jarang kata tersebut muncul dalam dataset secara keseluruhan

2.Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks.
Setelah melakukan fit dan transformasi menggunakan TfidfVectorizer, langkah-langkah yang dilakukan adalah sebagai berikut:

- `tf.fit_transform(movie_new['genre'])`:

  - `fit`: Menghitung dan membangun model berdasarkan data genre film yang ada. Proses ini mengidentifikasi kata-kata unik dalam kolom genre dan menghitung seberapa sering masing-masing kata muncul di seluruh dataset.
  - `transform`: Menggunakan model yang dibangun oleh fit untuk mengubah data genre menjadi matriks TF-IDF. Matriks ini adalah representasi numerik dari genre film di dataset, di mana setiap baris mewakili satu film, dan setiap kolom mewakili kata-kata yang ditemukan di genre.

- `tfidf_matrix.shape`:

  Ini akan memberikan dimensi dari matriks TF-IDF yang dihasilkan, yaitu jumlah baris dan kolom.
    - Jumlah baris: Jumlah film yang ada dalam dataset.
    - Jumlah kolom: Jumlah kata unik yang ditemukan dalam genre film.

Dengan kata lain, tfidf_matrix adalah matriks yang menggambarkan setiap film berdasarkan genre-nya dalam bentuk angka. Setiap nilai dalam matriks mewakili nilai TF-IDF untuk kata tertentu pada film tertentu.
"""

tfidf_matrix = tf.fit_transform(movie_new['genre'])
tfidf_matrix.shape

"""Hasil (1554, 24) menunjukkan bahwa matriks TF-IDF yang dihasilkan memiliki:

- 1554 baris: Ini menunjukkan bahwa ada 1554 film dalam dataset Anda.
- 24 kolom: Ini menunjukkan ada 24 kata unik yang ditemukan dalam genre film di dataset tersebut. Setiap kolom mewakili kata unik yang ada dalam genre film.

3.Menghasilkan vektor tf-idf dalam bentuk matriks, menggunakan fungsi `todense()`.
Proses yang dilakukan dengan menggunakan `todense()` pada matriks TF-IDF menghasilkan representasi matriks dalam bentuk dense (padat) yang menggantikan format sparse sebelumnya. Berikut adalah penjelasan mengenai hasil tersebut:

**Matriks Dense**: Dengan menggunakan `.todense()`, matriks TF-IDF yang awalnya sparse (hanya menyimpan nilai yang ada dan menghemat memori) diubah menjadi dense, yang menyimpan semua nilai, termasuk nol, di setiap elemen dari matriks.
"""

tfidf_matrix.todense()

"""Matriks tersebut memiliki 1554 baris (untuk 1554 film) dan 24 kolom (untuk 24 kata unik dari genre film). Setiap nilai dalam matriks ini menunjukkan bobot TF-IDF dari kata tertentu dalam genre film yang bersangkutan.

4.Lihat matriks tf-idf untuk beberapa movie (movie_name) dan genre
"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movie_new.movie_name
).sample(22, axis=1).sample(10, axis=0)

""" **Cosine Similarity**

5.Menghitung kesamaan antar film berdasarkan vektor tf-idf menggunakan cosine similarity.
Membuat dataframe kesamaan antar film (cosine_sim_df). Proses Cosine Similarity digunakan untuk mengukur seberapa mirip dua film berdasarkan vektor TF-IDF yang telah dihitung sebelumnya. Cosine similarity menghitung kemiripan dua vektor berdasarkan sudut antara keduanya, dengan hasil nilai antara 0 hingga 1.

Dengan fungsi `cosine_similarity()`, kita mendapatkan matriks kesamaan antar film berdasarkan vektor TF-IDF mereka.
Setiap elemen dalam matriks cosine_sim menunjukkan tingkat kesamaan antara dua film. Misalnya, elemen pada posisi (i, j) menunjukkan seberapa mirip film ke-i dengan film ke-j.
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Hasil matriks cosine_sim yang Anda tunjukkan adalah hasil perhitungan cosine similarity antara film-film berdasarkan genre mereka yang telah diubah menjadi vektor menggunakan TF-IDF. Berikut adalah penjelasan singkat tentang apa yang ditunjukkan oleh nilai-nilai tersebut:

1. Diagonal Utama:

  Nilai pada diagonal utama adalah 1.0, yang berarti setiap film memiliki kesamaan 100% dengan dirinya sendiri. Contohnya:
  - Baris pertama dan kolom pertama: 1.0 (Film pertama dengan film pertama).
  - Baris kedua dan kolom kedua: 1.0 (Film kedua dengan film kedua), dan seterusnya.

2. Nilai Non-Diagonal:

  Nilai-nilai di luar diagonal menunjukkan tingkat kesamaan antara dua film yang berbeda. Misalnya:
  - Nilai 0.80472348 pada posisi (0, 1) menunjukkan bahwa film pertama memiliki kesamaan 80.47% dengan film kedua.
  - Nilai 0.1808617 pada posisi (0, 2) menunjukkan bahwa film pertama memiliki kesamaan 18.09% dengan film ketiga.

3. Interpretasi Nilai:

  - Nilai 1.0 berarti kesamaan sempurna (film yang sama).
  - Nilai lebih besar dari 0 tetapi kurang dari 1 menunjukkan tingkat kemiripan tertentu.
  - Nilai yang lebih rendah (misalnya 0.0 atau sangat dekat dengan 0) menunjukkan tidak ada kesamaan atau hubungan yang sangat lemah antara film-film tersebut.
  
  Contoh:

  - Baris pertama, kolom kedua (0.80472348) menunjukkan bahwa film pertama cukup mirip dengan film kedua (80.47% mirip).
  - Baris pertama, kolom ketiga (0.1808617) menunjukkan bahwa film pertama hanya sedikit mirip dengan film ketiga (18.09% mirip).

6.Membuat dataframe dari variabel cosine_sim_df dengan baris dan kolom berupa nama movie, serta melihat kesamaan matrix dari setiap movie.
Pada langkah ini, kita membuat sebuah DataFrame bernama cosine_sim_df yang berisi hasil perhitungan cosine similarity antar film berdasarkan genre mereka. Setiap baris dan kolom pada DataFrame ini mewakili nama film, dan nilai di dalamnya adalah nilai kesamaan antara dua film tersebut.

1. Matriks Cosine Similarity:

  Kita telah menghitung cosine similarity antara semua film, yang menghasilkan matriks dua dimensi dengan ukuran 1554x1554. Matriks ini menunjukkan tingkat kesamaan antara setiap pasang film berdasarkan genre mereka.
2. Pembuatan DataFrame:

  DataFrame cosine_sim_df dibentuk dengan menggunakan hasil dari matriks cosine similarity dan menambahkan nama film sebagai indeks dan kolom.

  Pada DataFrame ini, setiap nilai (sel) menunjukkan tingkat kesamaan antara dua film yang bersangkutan.
"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['movie_name'], columns=movie_new['movie_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Pada contoh hasil yang ditampilkan, setiap angka menunjukkan tingkat kesamaan antara film di baris dan kolom tersebut:
1. Film yang berada di baris "**Auntie Mame (1958)**" dan kolom "**Flawless (1999)**" memiliki tingkat kesamaan **0.600342**.
2. Film "**Ice Storm, The (1997)**" dan "**Flawless (1999)**" memiliki tingkat kesamaan **1.0**, yang berarti mereka identik (memiliki genre yang sangat mirip).

## Mendapatkan Rekomendasi

1.Membuat fungsi movie_recommendations dengan beberapa parameter yang bertujuan untuk memberikan rekomendasi film berdasarkan kemiripan genre dari film yang diberikan. Berikut adalah penjelasan detail tentang cara kerjanya:

Parameter:

1. nama_movie: Nama film yang ingin Anda cari rekomendasinya berdasarkan kesamaan genre.
2. similarity_data: DataFrame yang berisi hasil dari perhitungan cosine similarity antar film (seperti cosine_sim_df).
3. items: DataFrame yang berisi informasi tentang film, seperti nama film dan genre. Pada contoh ini, movie_new[['movie_name', 'genre']] digunakan.
4. k: Jumlah rekomendasi film yang ingin ditampilkan (misalnya, 5 film teratas yang paling mirip dengan film yang diberikan).

Langkah-langkah Fungsi:

1. Indexing dan Pengambilan Data:
- `similarity_data.loc[:, nama_movie]` mengambil kolom yang berisi kesamaan untuk film yang dimaksud (dengan nama nama_movie).
- `.to_numpy()` mengubahnya menjadi array NumPy, dan .argpartition(range(-1, -k, -1)) mencari indeks k teratas yang memiliki nilai kemiripan tertinggi (termasuk film yang paling mirip dengan film yang diberikan).

2. Mencari Film Terdekat:
Setelah mendapatkan indeks film yang paling mirip, kita ambil nama film yang sesuai dengan indeks tersebut, dan menggunakan .drop(nama_movie, errors='ignore') untuk menghapus film yang menjadi input dari hasil rekomendasi (agar tidak muncul dalam daftar rekomendasi).

3. Menggabungkan Data:
Film yang sudah dipilih berdasarkan kemiripan kemudian digabungkan dengan DataFrame items (yang berisi nama dan genre film) menggunakan fungsi merge() untuk menampilkan nama film beserta genre-nya.
"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=movie_new[['movie_name', 'genre']], k=5):

    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""2.Menerapkan kode di atas untuk menemukan rekomendasi movie yang mirip dengan Woodsman, The (2004). Untuk menemukan rekomendasi film yang mirip dengan "Woodsman, The (2004)", pertama-tama, kita dapat memeriksa data film tersebut di dalam DataFrame movie_new menggunakan perintah `movie_new[movie_new.movie_name.eq('Woodsman, The (2004)')]`. Setelah memastikan bahwa data film tersebut ada dalam dataset, kita kemudian menggunakan fungsi movie_recommendations yang telah didefinisikan sebelumnya. Fungsi ini menerima beberapa parameter, antara lain nama film (dalam hal ini "Woodsman, The (2004)"), data kemiripan antar film (cosine_sim_df), informasi film seperti nama dan genre `(movie_new[['movie_name', 'genre']])`, dan jumlah rekomendasi yang diinginkan (misalnya 5 film teratas)."""

movie_new[movie_new.movie_name.eq('Woodsman, The (2004)')]

"""3.Dari hasil di atas dapat dilihat bahwa pengguna menyukai movie yang berjudul Woodsman, The (2004) yang bergenre Drama.  
Mendapatkan rekomendasi movie yang mirip dengan Woodsman, The (2004).


"""

movie_recommendations('Woodsman, The (2004)')

"""Dengan menggunakan fungsi ini, kita akan mendapatkan 5 rekomendasi film yang paling mirip dengan "**Woodsman, The (2004)**" berdasarkan kesamaan genre dan fitur lainnya, yang dapat memberikan pengalaman menonton yang serupa.Lalu dari hasil rekomendasi di atas, diketahui bahwa **Woodsman, The (2004)** termasuk ke dalam genre Drama Dari 5 item yang direkomendasikan semuanya memiliki genre Drama (similar). Artinya, precision sistem kita sebesar 5/5 atau **100%**.

### **2. Collaborative Filtering**

1.Mengubah nama variabel ratings yang telah dibuat sebelumnya menjadi df.
"""

df = ratings
df

"""## Data Preparation

1.Pada tahap Data Preparation, kita mulai dengan melakukan **user encoding**, yang merupakan langkah penting untuk mengubah data kategorikal (seperti userId) menjadi format numerik yang dapat digunakan oleh algoritma machine learning.

Pertama-tama, kita mengambil semua nilai unik dari kolom userId dan mengubahnya menjadi sebuah list tanpa nilai yang sama, dengan menggunakan `df['userId']` `.unique()` `.tolist()`. Ini menghasilkan daftar semua ID pengguna yang ada di dataset.

Selanjutnya, kita melakukan proses encoding terhadap userId dengan cara membuat sebuah dictionary yang memetakan setiap ID pengguna ke angka numerik. Proses ini dilakukan dengan perintah `{x: i for i, x in enumerate(user_ids)}`, yang akan memberikan angka numerik yang unik untuk setiap userId.

Setelah itu, untuk mempermudah pemrosesan lebih lanjut, kita juga membuat dictionary yang membalikkan mapping tersebut, yaitu dari angka numerik kembali ke userId yang asli, menggunakan `{i: x for i, x in enumerate(user_ids)}`. Dengan demikian, kita memiliki dua mapping: satu dari userId ke angka numerik (user_to_user_encoded) dan satu lagi dari angka numerik kembali ke userId (user_encoded_to_user). Kedua dictionary ini sangat berguna dalam tahap pemodelan, terutama ketika kita perlu mengganti antara ID pengguna numerik
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Output yang ditampilkan adalah sebuah representasi dari dua hal:

1. List userID:
Ini adalah daftar ID pengguna yang bernomor dari 1 hingga 610, yang menunjukkan semua pengguna yang terdaftar. Masing-masing ID ini adalah entri untuk pengguna yang berbeda.

2. Encoded userID:
Ini adalah kamus (dictionary) yang memetakan setiap userID ke nilai integer yang dimulai dari 0 hingga 609. Jadi, ID pengguna yang asli dimulai dari 1, tetapi dalam encoding ini, ID tersebut diganti dengan urutan numerik mulai dari 0. Misalnya:
- userID 1 menjadi 0
- userID 2 menjadi 1
- userID 3 menjadi 2, dan seterusnya.

2.Selanjutnya, lakukan hal yang sama pada fitur ‚ÄòmovieId‚Äô.
"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.

# Mapping userId ke dataframe genres
df['genres'] = df['userId'].map(user_to_user_encoded)

# Mapping movieD ke dataframe movies
df['movies'] = df['movieId'].map(movie_to_movie_encoded)

"""3.Terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah movie, dan mengubah nilai rating menjadi float, cek nilai minimum dan maximum. Pertama, kode menghitung jumlah pengguna (num_users) dengan melihat panjang dari kamus `user_to_user_encoded`, yang berisi pemetaan pengguna asli ke ID terencode.

Selanjutnya, kode menghitung jumlah film (num_movie) dengan menghitung panjang dari kamus `movie_encoded_to_movie`, yang memetakan ID film terencode ke ID asli. Kemudian, kode mengonversi kolom rating menjadi tipe data float32 agar konsisten untuk analisis lebih lanjut.

Setelah itu, kode mencari nilai rating minimum (**min_rating**) dan maksimum (**max_rating**) dalam dataset.
"""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['ratings'] = df['rating'].values.astype(np.float32)
min_rating = min(df['rating'])
max_rating = max(df['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Informasi tersebut dicetak dalam format yang jelas, memberikan gambaran mengenai jumlah pengguna, jumlah film, dan rentang rating dalam dataset, seperti jumlah pengguna 610, jumlah film 9724, dan rentang rating antara 0.5 hingga 5.0.

4.Membagi Data untuk Training dan Validasi
"""

df = df.sample(frac=1, random_state=42)
df

"""5.Melakukan pembagian data menjadi dua bagian:
- data training dan data validasi dengan komposisi 80:20.
- **Variabel x** berisi fitur yang digunakan untuk pelatihan, yaitu kolom genres dan movies, yang kemudian diubah menjadi array nilai dengan .values.
- **Variabel y** berisi target atau nilai rating yang telah dinormalisasi antara 0 dan 1 dengan menggunakan rumus (x - min_rating) / (max_rating - min_rating).

Setelah itu, indeks untuk data training (train_indices) dihitung sebagai 80% dari jumlah total baris dalam dataset. Data x dan y kemudian dibagi menjadi dua subset:
- data pelatihan (x_train dan y_train) yang berisi 80% dari data awal
- data validasi (x_val dan y_val) yang berisi 20% sisanya.
"""

x = df[['genres', 'movies']].values
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""6.Mempersiapkan model untuk proses training

"""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movie_embedding = layers.Embedding(
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x)

"""Pada kode di atas, model RecommenderNet yang menggunakan TensorFlow dan Keras didefinisikan untuk melakukan rekomendasi berbasis pembelajaran terawasi. Model ini menggunakan teknik embedding untuk mengonversi pengguna dan film menjadi vektor berdimensi rendah yang dapat dipelajari.

1. __init__ Method:

  - Inisialisasi parameter yang diperlukan, seperti jumlah pengguna (num_users), jumlah film (num_movie), dan ukuran embedding (embedding_size).
  - user_embedding dan movie_embedding masing-masing berfungsi untuk mengonversi ID pengguna dan film ke dalam vektor embedding berdimensi embedding_size. Vektor ini diinisialisasi dengan distribusi normal dan diberi regulasi L2 untuk mencegah overfitting.
  - user_bias dan movie_bias digunakan untuk menyimpan bias (penyimpangan) untuk setiap pengguna dan film, yang juga diinisialisasi dengan embedding satu dimensi.

2. call Method:

  - Metode ini mendefinisikan bagaimana input diproses selama tahap forward pass.
  - inputs adalah tensor dengan dua kolom, masing-masing mewakili ID pengguna dan ID film.
  - Vektor untuk pengguna (user_vector) dan film (movie_vector) dihitung melalui embedding. Bias untuk pengguna dan film juga dihitung.
  - dot_user_movie adalah hasil perkalian titik antara vektor pengguna dan film, yang menunjukkan interaksi antara pengguna dan film.
  - Akhirnya, hasilnya adalah penjumlahan dari dot_user_movie, user_bias, dan movie_bias, dan hasilnya diteruskan ke fungsi aktivasi sigmoid untuk memberikan output antara 0 dan 1, yang mencerminkan prediksi rating untuk pengguna terhadap film tersebut.

## Evaluation

1.Selanjutnya kita melakukan proses compile pada model **RecommenderNet** untuk persiapan pelatihan dan evaluasi dengan menggunakan metrik RMSE (Root Mean Squared Error).
"""

model = RecommenderNet(num_users, num_movie, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

callbacks = [EarlyStopping(monitor= 'loss', patience= 10 , restore_best_weights= True)]

"""Berikut penjelasan tentang langkah-langkah proses di atas tersebut:

- Model Initialization:

  `model = RecommenderNet(num_users, num_movie, 50)` menginisialisasi objek RecommenderNet dengan jumlah pengguna (num_users), jumlah film (num_movie), dan ukuran embedding (50).

- Model Compile:

  - `model.compile` digunakan untuk mengonfigurasi model sebelum pelatihan.
  - Loss Function: `tf.keras.losses.BinaryCrossentropy()` digunakan sebagai fungsi kerugian, yang cocok untuk tugas prediksi biner (rating dapat dianggap sebagai nilai antara 0 dan 1, meskipun dalam praktiknya, Anda mungkin lebih suka menggunakan loss lain seperti MSE untuk prediksi nilai kontinu).
  - Optimizer: `keras.optimizers.Adam(learning_rate=0.001)` digunakan sebagai algoritma optimasi, yang sering digunakan untuk pelatihan model deep learning. Learning rate diatur menjadi 0.001.
  - Metrics: `tf.keras.metrics.RootMeanSquaredError()` dipilih sebagai metrik evaluasi, yang mengukur seberapa baik model memprediksi rating yang benar berdasarkan RMSE. RMSE dihitung dengan mengambil akar kuadrat dari rata-rata kesalahan kuadrat antara prediksi dan nilai aktual.

- Callbacks:

  - callbacks = `[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]` adalah callback untuk menghentikan pelatihan lebih awal jika tidak ada peningkatan pada fungsi kerugian selama 10 epoch berturut-turut (patience=10).
  - `restore_best_weights=True` memastikan bahwa bobot model dikembalikan ke keadaan terbaik (yang menghasilkan nilai kerugian terendah) setelah pelatihan dihentikan.

2.Memulai proses training dengan batch size sebesar 64 serta epoch 100 kali
"""

history = model.fit(
    x = x_train,
    y = y_train,
    callbacks=callbacks,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""model rekomendasi yang dikembangkan menunjukkan perbaikan dalam metrik RMSE selama pelatihan. Pada **epoch ke-20**, nilai RMSE pada data pelatihan mencapai **0.1951**, sementara pada data validasi mencapai **0.2079**. Nilai RMSE terus menunjukkan penurunan, yang menunjukkan bahwa model semakin akurat dalam memprediksi rating. Penggunaan callback EarlyStopping membantu mencegah overfitting dengan menghentikan pelatihan lebih awal jika tidak ada peningkatan signifikan dalam loss. Proses pelatihan dengan batch size 64 dan 100 epoch memastikan model dapat belajar secara efektif, dengan hasil yang baik baik pada data pelatihan maupun data validasi.

3.Melakukan Visualisasi Metrik dengan plot untuk melihat visualisasi proses training
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""dari visualisasi proses training model di atas model berhenti di epochs sekitar 20. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.195 dan error pada data validasi sebesar 0.207.

4.Mendapatkan Rekomendasi movie
"""

movie_df = movie_new
df = pd.read_csv('movie-recommendation-data/ml-latest-small/ratings.csv')


user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]


movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""Untuk mendapatkan rekomendasi film, pertama-tama kita mengambil satu pengguna secara acak dari data ratings dan menemukan film-film yang telah ditonton oleh pengguna tersebut. Kemudian, kita mencari daftar film yang belum ditonton oleh pengguna dengan mengecualikan film yang sudah ada dalam data movie_watched_by_user.

Selanjutnya, kita mengonversi ID film yang belum ditonton menjadi ID yang telah dienkode menggunakan movie_to_movie_encoded. Setelah itu, kita menyiapkan array input untuk model rekomendasi, dengan menggabungkan ID pengguna yang sudah dienkode dan ID film yang belum ditonton. Array ini akan digunakan sebagai input untuk model yang telah dilatih untuk menghasilkan prediksi rating untuk setiap film yang belum ditonton oleh pengguna tersebut. Dengan demikian, kita bisa memberikan rekomendasi film berdasarkan prediksi rating tersebut.

5.Untuk memperoleh rekomendasi movies, gunakan fungsi model.predict() dari library Keras dengan menerapkan kode berikut.
Kode di bawah ini berfungsi untuk memberikan rekomendasi film kepada pengguna berdasarkan model yang telah dilatih. Berikut adalah penjelasan singkat mengenai langkah-langkah kode tersebut:

1. Memprediksi Rating untuk Film yang Belum Ditonton: Menggunakan fungsi model.predict() untuk memprediksi rating dari film yang belum ditonton oleh pengguna. Hasil prediksi kemudian di-flatten agar menjadi array satu dimensi.

2. Mengambil Top 10 Rekomendasi: Menggunakan argsort() untuk mengurutkan rating yang diprediksi secara menurun, dan mengambil 10 rating tertinggi (top 10).

3. Mendapatkan ID Film yang Direkomendasikan: Menggunakan indeks hasil pengurutan untuk mendapatkan ID film yang sesuai dengan rating tertinggi yang diprediksi. ID film yang direkomendasikan kemudian dipetakan kembali ke ID asli.

4. Menampilkan Film yang Sudah Ditonton oleh Pengguna: Menampilkan 5 film yang telah ditonton oleh pengguna, disortir berdasarkan rating tertinggi.

5. Menampilkan Rekomendasi Top 10 Film: Menampilkan 10 film teratas yang direkomendasikan berdasarkan hasil prediksi rating yang telah dilakukan.
"""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing movie recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movie with highest ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)

"""Hasil di atas menunjukkan rekomendasi film untuk pengguna dengan **ID 525**. Berikut adalah penjelasan dari output tersebut:

1. 5 Film dengan Rating Tertinggi yang Sudah Ditonton Pengguna:

  Menampilkan 5 film yang telah ditonton oleh pengguna dengan rating tertinggi, di mana film-film ini adalah "**Ferris Bueller's Day Off (1986)**", "**Dogma (1999)**", dan "**The Virgin Suicides (1999)**".
2. 10 Film Rekomendasi Teratas:

  Menampilkan 10 film yang direkomendasikan untuk pengguna berdasarkan prediksi model, yang terdiri dari film dengan genre seperti drama, aksi, dan kriminal. Contohnya termasuk "**Pulp Fiction (1994)**", "**One Flew Over the Cuckoo's Nest (1975)**", dan "**The Good, the Bad and the Ugly (1966)**".

Rekomendasi ini menunjukkan film-film yang kemungkinan akan disukai oleh pengguna berdasarkan pola rating dan genre film yang telah ditonton sebelumnya.
"""